{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 0s 149us/step - loss: 0.9686 - val_loss: 0.4648\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.3150 - val_loss: 0.2820\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 45us/step - loss: 0.2920 - val_loss: 0.3115\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 39us/step - loss: 0.3252 - val_loss: 0.2843\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 47us/step - loss: 0.3336 - val_loss: 0.2588\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 55us/step - loss: 0.2860 - val_loss: 0.2842\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 56us/step - loss: 0.2938 - val_loss: 0.3215\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 51us/step - loss: 0.2922 - val_loss: 0.3875\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 53us/step - loss: 0.3086 - val_loss: 0.4300\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 53us/step - loss: 0.3181 - val_loss: 0.2892\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 53us/step - loss: 0.2886 - val_loss: 0.3287\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 45us/step - loss: 0.2885 - val_loss: 0.2584\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.2911 - val_loss: 0.3814\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 49us/step - loss: 0.3237 - val_loss: 0.2984\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 41us/step - loss: 0.2803 - val_loss: 0.3590\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 41us/step - loss: 0.2906 - val_loss: 0.5172\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 48us/step - loss: 0.3005 - val_loss: 0.3437\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 48us/step - loss: 0.2916 - val_loss: 0.3018\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.3048 - val_loss: 0.4423\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 42us/step - loss: 0.3068 - val_loss: 0.2455\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 43us/step - loss: 0.2950 - val_loss: 0.2548\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 50us/step - loss: 0.2896 - val_loss: 0.2373\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 46us/step - loss: 0.3057 - val_loss: 0.2807\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 34us/step - loss: 0.2989 - val_loss: 0.2775\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 39us/step - loss: 0.2908 - val_loss: 0.3859\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 45us/step - loss: 0.2999 - val_loss: 0.3960\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 46us/step - loss: 0.3073 - val_loss: 0.4383\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 45us/step - loss: 0.2791 - val_loss: 0.3184\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 47us/step - loss: 0.2802 - val_loss: 0.2600\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 47us/step - loss: 0.3140 - val_loss: 0.6269\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.3143 - val_loss: 0.3514\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 40us/step - loss: 0.3069 - val_loss: 0.3936\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 36us/step - loss: 0.2929 - val_loss: 0.3058\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 35us/step - loss: 0.2865 - val_loss: 0.6174\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 39us/step - loss: 0.3070 - val_loss: 0.2488\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.2980 - val_loss: 0.2479\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 42us/step - loss: 0.2896 - val_loss: 0.3198\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 39us/step - loss: 0.2977 - val_loss: 0.3984\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 36us/step - loss: 0.3198 - val_loss: 0.2797\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 41us/step - loss: 0.2718 - val_loss: 0.2716\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 42us/step - loss: 0.2933 - val_loss: 0.2539\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.090 - 0s 38us/step - loss: 0.3047 - val_loss: 0.3956\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.2879 - val_loss: 0.2710\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 38us/step - loss: 0.3003 - val_loss: 0.3100\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 39us/step - loss: 0.2827 - val_loss: 0.2681\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 43us/step - loss: 0.2978 - val_loss: 0.2571\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 38us/step - loss: 0.2877 - val_loss: 0.3074\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 37us/step - loss: 0.2874 - val_loss: 0.3211\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 42us/step - loss: 0.3216 - val_loss: 0.2696\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.2789 - val_loss: 0.2488\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 44us/step - loss: 0.3066 - val_loss: 0.2439\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 45us/step - loss: 0.2920 - val_loss: 0.3154\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 41us/step - loss: 0.2927 - val_loss: 0.2530\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 38us/step - loss: 0.2811 - val_loss: 0.3128\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 42us/step - loss: 0.2930 - val_loss: 0.2423\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 43us/step - loss: 0.2916 - val_loss: 0.2873\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 49us/step - loss: 0.2774 - val_loss: 0.3113\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 38us/step - loss: 0.2843 - val_loss: 0.3319\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 37us/step - loss: 0.2838 - val_loss: 0.2782\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 37us/step - loss: 0.3347 - val_loss: 0.2855\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 37us/step - loss: 0.3173 - val_loss: 0.2631\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 42us/step - loss: 0.3171 - val_loss: 0.2484\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 38us/step - loss: 0.2937 - val_loss: 0.2569\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 36us/step - loss: 0.3211 - val_loss: 0.2814\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 40us/step - loss: 0.3295 - val_loss: 0.2523\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 39us/step - loss: 0.2814 - val_loss: 0.3297\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 48us/step - loss: 0.2971 - val_loss: 0.2905\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 45us/step - loss: 0.3246 - val_loss: 0.3157\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 37us/step - loss: 0.2923 - val_loss: 0.3145\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 40us/step - loss: 0.2845 - val_loss: 0.2474\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 42us/step - loss: 0.2885 - val_loss: 0.2909\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 33us/step - loss: 0.2936 - val_loss: 0.2366\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 35us/step - loss: 0.3037 - val_loss: 0.2885\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 39us/step - loss: 0.2918 - val_loss: 0.2995\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 41us/step - loss: 0.2794 - val_loss: 0.5625\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 40us/step - loss: 0.2864 - val_loss: 0.3657\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 34us/step - loss: 0.2922 - val_loss: 0.2452\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 37us/step - loss: 0.2774 - val_loss: 0.2528\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 43us/step - loss: 0.2729 - val_loss: 0.2939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 45us/step - loss: 0.2874 - val_loss: 0.2565\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 41us/step - loss: 0.2903 - val_loss: 0.4111\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 48us/step - loss: 0.2900 - val_loss: 0.2520\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 53us/step - loss: 0.2846 - val_loss: 0.3376\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 57us/step - loss: 0.2762 - val_loss: 0.2417\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 46us/step - loss: 0.2826 - val_loss: 0.2879\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 54us/step - loss: 0.2872 - val_loss: 0.3046\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 58us/step - loss: 0.2800 - val_loss: 0.2745\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 53us/step - loss: 0.2792 - val_loss: 0.2706\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 51us/step - loss: 0.2808 - val_loss: 0.5375\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 50us/step - loss: 0.3162 - val_loss: 0.2485\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 52us/step - loss: 0.3160 - val_loss: 0.3399\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 50us/step - loss: 0.2798 - val_loss: 0.2396\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 48us/step - loss: 0.3040 - val_loss: 0.2499\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 50us/step - loss: 0.3037 - val_loss: 0.2319\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 47us/step - loss: 0.2941 - val_loss: 0.3177\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 51us/step - loss: 0.2853 - val_loss: 0.2515\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 60us/step - loss: 0.2854 - val_loss: 0.2917\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 51us/step - loss: 0.2981 - val_loss: 0.3081\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 53us/step - loss: 0.2846 - val_loss: 0.2533\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 53us/step - loss: 0.2858 - val_loss: 0.2546\n",
      "Baseline Mean Abs Err: 6.6 | Baseline Mean Squared Err: 84.62 | Baseline Mean Abs %Err: 0.30\n",
      "Model Mean Abs Err: 3.4 | Model Mean Squared Err: 22.66 | Model Mean Abs %Err: 0.15\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# Mean and variance normalize input data.\n",
    "x_mean, x_stddev = x_train.mean(axis = 0), x_train.std(axis = 0)\n",
    "x_train = (x_train - x_mean) / x_stddev\n",
    "x_test = (x_test - x_mean) / x_stddev\n",
    "\n",
    "y_mean, y_stddev = y_train.mean(), y_train.std()\n",
    "y_train = (y_train - y_mean) / y_stddev\n",
    "y_test = (y_test - y_mean) / y_stddev\n",
    "\n",
    "input_tensor = Input(shape = (13,))\n",
    "output_tensor = Dense(1, activation = 'linear')(input_tensor)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "optimizer = SGD(lr = 0.1)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mse',\n",
    "    optimizer = optimizer\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data = (x_test, y_test),\n",
    "    batch_size = 32,\n",
    "    epochs = 100\n",
    ")\n",
    "\n",
    "# How to interpret the MSE loss. The MSE is an estimate of *variance*,\n",
    "# which is dispersion from the mean.\n",
    "#\n",
    "# Because we standardized y_train to have variance 1.0, that means\n",
    "# that the MSE of guessing the mean value (which was itself set to\n",
    "# zero) would be 1.0.\n",
    "#\n",
    "# If we train a model and have a test set MSE of 0.27, that means that\n",
    "# the variance in output, *after* we have factored out the part of the\n",
    "# output explained by the X variables, is 0.27.\n",
    "#\n",
    "# Put another way: the X variables explain 73% of the variance in\n",
    "# house prices.\n",
    "\n",
    "def calc_errors(y_train, y_predictions):\n",
    "    absolute_errors = np.abs(y_train - y_predictions) * y_stddev\n",
    "    mean_absolute_error = np.mean(absolute_errors)\n",
    "\n",
    "    squared_errors = ((y_train - y_predictions) * y_stddev) ** 2\n",
    "    mean_squared_error = np.mean(squared_errors)\n",
    "\n",
    "    mean_absolute_percent_error = np.mean(\n",
    "        np.abs(absolute_errors / y_mean)\n",
    "    )\n",
    "\n",
    "    return (mean_absolute_error, mean_squared_error, mean_absolute_percent_error)\n",
    "\n",
    "(mean_absolute_error, mean_squared_error, mean_absolute_percent_error) = calc_errors(\n",
    "    y_train,\n",
    "    y_train.mean()\n",
    ")\n",
    "print(\n",
    "    f\"Baseline Mean Abs Err: {mean_absolute_error:0.1f} | \"\n",
    "    f\"Baseline Mean Squared Err: {mean_squared_error:0.2f} | \"\n",
    "    f\"Baseline Mean Abs %Err: {mean_absolute_percent_error:0.2f}\"\n",
    ")\n",
    "\n",
    "(mean_absolute_error, mean_squared_error, mean_absolute_percent_error) = calc_errors(\n",
    "    y_train,\n",
    "    # model.predict gives us a (404, 1) matrix which won't play well\n",
    "    # with our (404,) shape y_train. Thus we reshape the output to\n",
    "    # (404,).\n",
    "    model.predict(x_train).reshape((-1))\n",
    ")\n",
    "print(\n",
    "    f\"Model Mean Abs Err: {mean_absolute_error:0.1f} | \"\n",
    "    f\"Model Mean Squared Err: {mean_squared_error:0.2f} | \"\n",
    "    f\"Model Mean Abs %Err: {mean_absolute_percent_error:0.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
