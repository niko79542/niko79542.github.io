{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boltzman - Bostom Home Prices (Keras)\n",
    "\n",
    "Redoing one of the earlier problems using Keras, just to get the hang of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try to get out inputs and outputs as close to variance 1 as possible.  This makes it easier for gradient descent to converge\n",
    "\n",
    "y_stddev = y_train.std()\n",
    "y_mean = y_train.mean()\n",
    "\n",
    "def normalize_data(x):\n",
    "    x_mean = x.mean(axis=0)\n",
    "    x_stddev = x.std(axis=0)\n",
    "    return (x - x_mean) / x_stddev \n",
    "\n",
    "x_train = normalize_data(x_train) \n",
    "y_train = normalize_data(y_train)\n",
    "x_test = normalize_data(x_test)\n",
    "y_test = normalize_data(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "404/404 [==============================] - 0s 385us/step - loss: 1.5247\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.5567\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 84us/step - loss: 0.4251\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.3637\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 80us/step - loss: 0.3303\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.3100\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 90us/step - loss: 0.2969\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 86us/step - loss: 0.2882\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.2834\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 79us/step - loss: 0.2797\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 91us/step - loss: 0.2754\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.2750\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 59us/step - loss: 0.2725\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.2716\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.2696\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 86us/step - loss: 0.2685\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 88us/step - loss: 0.2684\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 73us/step - loss: 0.2675\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2678\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 71us/step - loss: 0.2673\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 70us/step - loss: 0.2660\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 68us/step - loss: 0.2657\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2669\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 73us/step - loss: 0.2664\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 73us/step - loss: 0.2661\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 71us/step - loss: 0.2657\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 84us/step - loss: 0.2652\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 73us/step - loss: 0.2654\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 79us/step - loss: 0.2664\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 87us/step - loss: 0.2659\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.2650\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 72us/step - loss: 0.2663\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.2658\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 81us/step - loss: 0.2680\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 84us/step - loss: 0.2664\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 79us/step - loss: 0.2654\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 84us/step - loss: 0.2646\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 76us/step - loss: 0.2684\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 71us/step - loss: 0.2681\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 79us/step - loss: 0.2643\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 80us/step - loss: 0.2651\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2663\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2646\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 73us/step - loss: 0.2661\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 70us/step - loss: 0.2652\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.2652\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.2651\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.2663\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.2656\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2666\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 84us/step - loss: 0.2659\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 67us/step - loss: 0.2662\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 76us/step - loss: 0.2657\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 70us/step - loss: 0.2640\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 77us/step - loss: 0.2672\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2639\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 84us/step - loss: 0.2653\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 76us/step - loss: 0.2646\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 72us/step - loss: 0.2648\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 66us/step - loss: 0.2665\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 66us/step - loss: 0.2658\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 79us/step - loss: 0.2654\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 83us/step - loss: 0.2649\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 70us/step - loss: 0.2657\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 62us/step - loss: 0.2661\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 63us/step - loss: 0.2656\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 81us/step - loss: 0.2654\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.2647\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 70us/step - loss: 0.2651\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 67us/step - loss: 0.2643\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 56us/step - loss: 0.2666\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 67us/step - loss: 0.2650\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 60us/step - loss: 0.2671\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2654\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2650\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 61us/step - loss: 0.2644\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 72us/step - loss: 0.2659\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 66us/step - loss: 0.2648\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 63us/step - loss: 0.2627\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 74us/step - loss: 0.2656\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 72us/step - loss: 0.2657\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 80us/step - loss: 0.2644\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 58us/step - loss: 0.2645\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 79us/step - loss: 0.2646\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 61us/step - loss: 0.2652\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 69us/step - loss: 0.2652\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 60us/step - loss: 0.2644\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 76us/step - loss: 0.2644\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 71us/step - loss: 0.2658\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 58us/step - loss: 0.2649\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 69us/step - loss: 0.2671\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 72us/step - loss: 0.2648\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 71us/step - loss: 0.2669\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 65us/step - loss: 0.2662\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 76us/step - loss: 0.2648\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 71us/step - loss: 0.2658\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 58us/step - loss: 0.2656\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 70us/step - loss: 0.2679\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 64us/step - loss: 0.2667\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 78us/step - loss: 0.2650\n",
      "102/102 [==============================] - 0s 755us/step\n",
      "0.24743249837089987\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import logging\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(1, input_shape=(13,)), # We want 1 layer.  with one output.  We have 13 weigths\n",
    "    Activation('linear'),  # activation function\n",
    "])\n",
    "\n",
    "optimizer = SGD(lr = 0.01) # stochastic gradient descent with learning rate.\n",
    "model.compile(loss='mse', optimizer=optimizer) # model will minimize mean squared error.  \n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=100) # training...\n",
    "score = model.evaluate(x_test, y_test, batch_size=16) # evauluate on test data.\n",
    "\n",
    "# logging.info('mse=%f,' % (score))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Mean Abs Err: 6.6 | Baseline Mean Squared Err: 84.62 | Baseline Mean Abs %Err: 0.30\n",
      "Model Mean Abs Err: 3.4 | Model Mean Squared Err: 22.13 | Model Mean Abs %Err: 0.15\n"
     ]
    }
   ],
   "source": [
    "def calc_errors(y_train, y_predictions):\n",
    "    absolute_errors = np.abs(y_train - y_predictions) * y_stddev\n",
    "    mean_absolute_error = np.mean(absolute_errors)\n",
    "\n",
    "    squared_errors = ((y_train - y_predictions) * y_stddev) ** 2\n",
    "    mean_squared_error = np.mean(squared_errors)\n",
    "\n",
    "    mean_absolute_percent_error = np.mean(\n",
    "        np.abs(absolute_errors / y_mean)\n",
    "    )\n",
    "\n",
    "    return (mean_absolute_error, mean_squared_error, mean_absolute_percent_error)\n",
    "\n",
    "(mean_absolute_error, mean_squared_error, mean_absolute_percent_error) = calc_errors(\n",
    "    y_train,\n",
    "    y_train.mean()\n",
    ")\n",
    "print(\n",
    "    f\"Baseline Mean Abs Err: {mean_absolute_error:0.1f} | \"\n",
    "    f\"Baseline Mean Squared Err: {mean_squared_error:0.2f} | \"\n",
    "    f\"Baseline Mean Abs %Err: {mean_absolute_percent_error:0.2f}\"\n",
    ")\n",
    "\n",
    "(mean_absolute_error, mean_squared_error, mean_absolute_percent_error) = calc_errors(\n",
    "    y_train,\n",
    "    # model.predict gives us a (404, 1) matrix which won't play well\n",
    "    # with our (404,) shape y_train. Thus we reshape the output to\n",
    "    # (404,).\n",
    "    model.predict(x_train).reshape((-1))\n",
    ")\n",
    "print(\n",
    "    f\"Model Mean Abs Err: {mean_absolute_error:0.1f} | \"\n",
    "    f\"Model Mean Squared Err: {mean_squared_error:0.2f} | \"\n",
    "    f\"Model Mean Abs %Err: {mean_absolute_percent_error:0.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
